[{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in Deep Learning to develope model for analyzing how hidden factors, which could be related to economic conditions, investor behavior, or other mysterious influences, affect asset returns. The key benefits include reducing pricing errors and ensuring that the developed pricing model adheres to economic principles. Accomplishments:\nDeveloped and deployed an autoencoder model to generate accurate return forecasts, optimizing investment strategies. Transferable Skills:\nProficient in financial data analysis and forecasting methodologies. Skilled in applying Machine Learning techniques, especially Deep Learning models, to tabular data analysis. Responsibilities:\nDeveloped an autoencoder model for return forecast generation. Fine-tuning parameters for optimal performance. ","permalink":"http://localhost:1313/projects/lprojects/self-p2/","tags":["Python","Tensorflow2","Finance"],"title":"Return Forecasts using Conditional Autoconders"},{"categories":null,"contents":" Relevance to the Business:\nLeveraged my expertise in Deep Learning and Gen AI to develop AI-based tools for generating avatar for individual creators and influencers. The tool offers a new medium to express creativity and help to maintain a consistent and engaging online presence. Accomplishments:\nAn Application Programming Interface for AI Avatar generation tool. Transferable Skills:\nSolid understanding of image processing, data preprocessing, and model evaluation techniques Solid Understanding of Generative Deep Learning (Gan and Diffusion models), Responsibilities:\nDeveloped the Generative Deep Learning model, from conceptualization to implementation. Challenges and Difficulties:\nNavigated challenges related to dataset quality, model convergence, and computational resource management. ","permalink":"http://localhost:1313/projects/lprojects/self-p1/","tags":["Python","Pytorch","GenAI","Pytorch Lightning"],"title":"AI Avatar Generator"},{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"http://localhost:1313/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in Computer Vision and Deep Learning to develop object detection algorithms using 3D cameras/sensors (3D Object Detection Algorithms). These advancements significantly enhance robustness, and capabilities of autonomous systems across wide ranges of applications and industries.\nTargeted applications could be\nSelf-driving Cars: my algorithms help autonomous cars understand theirs surroundings Augmented Reality (AR) and Virtual Reality (VR): my algorithms facilitate the seamless integration of virtual objects into the physical world, elevating the user experience by providing realistic and immersive virtual environments. Industrial Automation: my algorithms can help to inspect components, detect infects automatically. Medical diagnosis: my algorithms can be used for tasks such as tumor detection and organ segmentation. Accomplishments:\nTwo publications about algorithms for 3D object detection. Transferable Skills:\nSolid Understanding of Computer Vision and Deep Learning models, 3D object modelling. Skilled in Python and C++ programming; and utilization of tensorflow, Computer Vision Responsibilities:\nDeveloped a prototype for 3D Object Detection systems, from conceptualization to implementation. ","permalink":"http://localhost:1313/projects/lprojects/self-p5/","tags":["Python","Tensorflow2","Computer Vision","Point Cloud","C++"],"title":"Point Cloud Based 3D Object Detection"},{"categories":null,"contents":" Relevance to the Business:\nLeveraged my expertise in deep learning and Natural Language Processing (NLP) to develop tools for enhancing efficient information retrieval in today\u0026rsquo;s data-driven environment. Targeted at business entities who improve customer support and productivity by automating the extraction of valuable insights from their vast databases. Accomplishments:\nDelivered an attractive Proof of Concept (PoC) to MTI and some private clients, showcasing practical applications. Transferable Skills:\nSolid Understanding of Deep Learning models for NLP, Skilled in Python programming and utilization of NLP libraries such as spaCy, NLTK, transfomer models from hugging face. Responsibilities:\nDeveloped a prototype for Q\u0026amp;A systems, from conceptualization to implementation. ","permalink":"http://localhost:1313/projects/lprojects/self-p4/","tags":["Python","Tensorflow2","GenAI","NLP"],"title":"Question Answering System"},{"categories":null,"contents":" Relevance to the Business:\nEnhance customer experience and engagement by providing tailored product or content suggestions. Accomplishments:\nImplemented collaborative filtering and content-based filtering techniques to generate personalized recommendations. Transferable Skills:\nProficient in machine learning algorithms including standard algorithms for Regression and Classification, Deep Learning constructs (RNN, CNN, Auto Encoders, GANs) and AI systems such as Voice to Text, NLP and Recommender systems. Understanding ML systems using Spark libraries such as ML Lib, Spark SQL. Responsibilities:\nDeveloped recommender systems for product recommendations. Challenges and Difficulties:\nNavigated challenges related to dataset quality, model convergence, and computational resource management. ","permalink":"http://localhost:1313/projects/lprojects/self-p3/","tags":["Python","Tensorflow2","Neo4j"],"title":"Recommendations System"},{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in machine learning, deep learning, and data analytics to pioneer the development of an innovative AI-driven tool for short-term weather forecasting, with a specific focus on predicting hailstorms. Targeted diverse spectrum of Japanese companies, primarily targeting the insurance and car dealership sectors, aimed at elevating risk assessment capabilities by providing exceptionally accurate forecasts. This enhancement in risk assessment holds particular significance for the insurance sector, where weather-related events can exert substantial financial implications. Accomplishments:\nDeveloped a Short-term Hail Nowcast prototype, surpassing the accuracy of the Japan Meteorological Agency\u0026rsquo;s (JMA) forecast system (72% vs. 55%). Delivered a compelling Proof of Concept (PoC) to MS\u0026amp;AD insurance group, showcasing practical applications and superior forecasting capabilities. Transferable Skills:\nAnalytical skills and Quantitative Analysis, Data visualization Knowledge of Geneartive AI Knowledge of Weather and Radar Meteorology. Leadership, project management, and problem-solving skills. Responsibilities:\nLed a data science team, ensuring collaboration between data scientists and industry experts. Mentor the junior team members and support them with technical issues. Translated specific needs of stakeholders into an optimized deep learning model. Challenges and Difficulties:\nRequired a deep understanding of meteorological data and generative deep learning techniques to provide accurate forecasts in a short time frame. Feedback and Endorsements:\nPositive feedback from stakeholders. Context:\nComprehensive background in deep learning and data analytics. Commitment to projects with direct business relevance, contributing to industry advancements. ","permalink":"http://localhost:1313/projects/lprojects/mti-p2/","tags":["Python","Pytorch","GenAI","Computer Vision","AWS","Gitlab"],"title":"Short-term Hail Nowcast Using AI for Extreme Weather Events"},{"categories":null,"contents":"Relevance to the Business:\nApplied machine learning, deep learning and data analytics expertise to develop a sophisticated typesetting tool. Targeted specifically for Japanese newspapers, aimed at enhancing efficiency, quality of layout design and cost reduction. Accomplishments:\nSecured a patent for the Typesetting API. Delivered a Proof of Concept (PoC) to renowned companies like Toshiba and Fujitsu. Transferable Skills:\nKnowledge of state of the art machine learning methodologies and their business applications in python (sklearn, pytorch, flask, fastapi) Knowledge of IT and Cluster technologies: Docker, Gitlab. Analytical skill, Data visualization, Constraint Programming and Deep Reinforcement Learning (Proximal Policy Optimization). Leadership, project management, and problem-solving skills. Responsibilities:\nLed a multidisciplinary team, ensuring collaboration between data scientist, software developers, data analyst, and industry experts. Mentor the junior team members and support them with technical issues. Translated specific needs of Japanese newspapers into an optimized machine learning model. Oversaw the end-to-end development of predictive models using advanced machine learning algorithms. Challenges and Difficulties:\nRequired understanding the unique preferences of the Japanese market, and design principles. Demonstrated problem-solving skills at the intersection of machine learning and Japanese design. Feedback and Endorsements:\nReceived positive feedback from stakeholders on efficiency and quality improvements. Endorsements affirm tangible contributions to the business landscape. Context:\nComprehensive background in deep learning and data analytics. Commitment to projects with direct business relevance, contributing to industry advancements. ","permalink":"http://localhost:1313/projects/lprojects/mti-p1/","tags":["Python","Pytorch","Reinforcement Learning","AWS",".NET","Gitlab"],"title":"Typesetting – AI-based Newspaper Placement Tool for the Japanese market."},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\nDon’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution. ","permalink":"http://localhost:1313/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"http://localhost:1313/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"http://localhost:1313/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":" \u0026emsp; The newsroom is a whirlwind of activity, with editors juggling deadlines, reporters chasing stories, and designers wrestling with stacks of paper and design software. Among these challenges, the process of typesetting – arranging articles, images, and advertisements on the page – stands out as a particularly time-consuming and labor-intensive task. But what if this critical step could be streamlined and enhanced with the power of artificial intelligence? See demonstration !!! I. The Pain Points of Traditional Typesetting \u0026emsp; Traditionally, typesetting is a manual and often tedious process. Designers meticulously arrange elements on the page, considering factors like headline size, image placement, and column widths. This meticulous work is prone to human error, leading to inconsistencies in layout and potential for missed deadlines. The pressure to meet tight deadlines adds to the stress, hindering creativity and the ability to explore diverse and innovative design solutions. The process is illustrated in the Figure below Typical typesetting process used in newspaper company\nFig 1. Current Manual Process 1 Fig 2. Manual Process - Making rough layout Fig 3. Manual Process - Making layout arrangement on computer The process last about 12 hours and it is very stressful.\nII. Solutions: Automating the Art of Layout \u0026emsp; By leveraging constraint optimization and Reinforcement Learning (a sub-field of Machine Learning) techniques, I developed a novel solution that automates the typesetting process, significantly reducing the time required and minimizing the risk of human errors. This AI solution was implemented as a proof of concept and was showcased to ToO newspaper company. Intelligent Content Placement: The AI system analyzes articles, images, and advertisements, intelligently suggesting optimal placements on the page. Automated Layout Generation: The AI can generate multiple layout options, allowing designers to quickly explore different possibilities and choose the most effective design. Image Optimization: The system automatically resizes and optimizes images for print, ensuring high-quality reproduction. Fig 4. The proposed automated typesetting process Fig 5. The proposed typesetting (left) process and visualization of the proposed framework (right) Fig 6. Visualization of states of the proposed framework III. The Benefits Speak for Themselves \u0026emsp; By automating many of the mundane tasks, AI-powered typesetting significantly enhances efficiency and productivity. Reduced Workload: Designers can spend less time on repetitive tasks and more time on creative aspects of design. Faster Turnaround Times: Newspapers can be produced more quickly, enabling faster news dissemination. Improved Consistency: AI helps ensure consistent layouts across different editions and publications, enhancing brand identity. Enhanced Creativity: Designers are empowered to explore a wider range of layout options and experiment with innovative design concepts. IV. Beyond Typesetting: A Catalyst for Innovation \u0026emsp; The successful application of AI in newspaper typesetting demonstrates its broader potential across various industries. Magazine and Book Publishing: Streamline the layout and design of magazines, books, and other print publications. Graphic Design and Advertising: Automate aspects of brochure, poster, and billboard design. Website and App Design: Assist in the creation of visually appealing and user-friendly interfaces. Industrial Manufacturing and Production: Optimize production processes and improve efficiency in various manufacturing settings. V. The Future of AI in Design \u0026emsp; The integration of AI into the design process marks a significant step forward. By automating repetitive tasks and augmenting human creativity, AI has the potential to revolutionize how we approach design in the 21st century. As AI technology continues to evolve, we can expect even more sophisticated and innovative applications in the years to come, ushering in a new era of creativity and efficiency across diverse industries. This blog post provides a glimpse into the transformative power of AI in the field of newspaper design. By embracing these innovative technologies, the publishing industry can not only improve its efficiency but also unlock new levels of creativity and innovation in the years to come.\nVI. Demonstrations ","permalink":"http://localhost:1313/blog/typesetting/","tags":["Python","Pytorch","Reinforcement Learning","Deep Learning","Constrained Programming"],"title":"Revolutionizing Newspaper Design: How AI is Automating Typesetting"},{"categories":null,"contents":"BOSH (Bosh Outer SHell) \u0026ldquo;\u0026hellip; is an open source tool for release engineering, deployment, lifecycle management, and monitoring of distributed systems.\u0026rdquo; And it\u0026rsquo;s amazingly powerful. This examples uses BOSH to provision an Alassian vendor app running on JDK along with the support Postgres database and agents to support it. The releases manages the health of services and will automatically provision, start/stop processes across the various services.\n","permalink":"http://localhost:1313/projects/creations/bosh-agents/","tags":["DevOps","BOSH","Java","Atlassian Ecosystem","monit","python","xml/xslt","bash/shell","REST APIs"],"title":"BOSH release for Bamboo \u0026 Remote Agents"},{"categories":null,"contents":"Intro Doesn\u0026rsquo;t matter whether it\u0026rsquo;s a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\nFirst it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026quot; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on. Once you implement SSL certificates on your server you\u0026rsquo;ll want to require secure connections using Apache\u0026rsquo;s rewrite module. Now I won\u0026rsquo;t dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\nCreating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026quot; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users) The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026rsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026rsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you\u0026rsquo;ll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You\u0026rsquo;ll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that\u0026rsquo;s easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You\u0026rsquo;ll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"http://localhost:1313/blog/force-ssl/","tags":["apache"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":"Multiple plugins used by thousands of teams that provide enhanced functionality of Atlassian’s core products (primarily JIRA and Bamboo) to enrich CI/CD capabilities, DevOps automation, or productivity. Functionality spans user interface, web services and persistence.\n","permalink":"http://localhost:1313/projects/creations/marketplace/","tags":["Java","Spring","REST APIs","Javascript","Atlassian Developer Ecosystem","Bamboo","JIRA","Bitbucket","Confluence","DevOps"],"title":"Atlassian Marketplace Plugins"},{"categories":null,"contents":"Provides required dependencies and additional utilities to simplify and codify the process of building, testing and delivering Atlassian plugins all the way to the live marketplace. Executes integration/AUT level tests against all stated compatible versions for the productUploads generated artifact to Atlassian marketplaceProvides corresponding metadata indicating version, release notes, and compatibility\n","permalink":"http://localhost:1313/projects/creations/docker-marketplace/","tags":["Docker","Maven","Java","Python","REST APIs","Bash/Shell"],"title":"Docker image for Bitbucket CI/CD Pipelines  \"shipit\""},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"http://localhost:1313/search/","tags":null,"title":"Search Results"},{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in Deep Learning to develope model for analyzing how hidden factors, which could be related to economic conditions, investor behavior, or other mysterious influences, affect asset returns. The key benefits include reducing pricing errors and ensuring that the developed pricing model adheres to economic principles. Accomplishments:\nDeveloped and deployed an autoencoder model to generate accurate return forecasts, optimizing investment strategies. Transferable Skills:\nProficient in financial data analysis and forecasting methodologies. Skilled in applying Machine Learning techniques, especially Deep Learning models, to tabular data analysis. Responsibilities:\nDeveloped an autoencoder model for return forecast generation. Fine-tuning parameters for optimal performance. ","permalink":"http://localhost:1313/projects/lprojects/self-p2/","tags":["Python","Tensorflow2","Finance"],"title":"Return Forecasts using Conditional Autoconders"},{"categories":null,"contents":" Relevance to the Business:\nLeveraged my expertise in Deep Learning and Gen AI to develop AI-based tools for generating avatar for individual creators and influencers. The tool offers a new medium to express creativity and help to maintain a consistent and engaging online presence. Accomplishments:\nAn Application Programming Interface for AI Avatar generation tool. Transferable Skills:\nSolid understanding of image processing, data preprocessing, and model evaluation techniques Solid Understanding of Generative Deep Learning (Gan and Diffusion models), Responsibilities:\nDeveloped the Generative Deep Learning model, from conceptualization to implementation. Challenges and Difficulties:\nNavigated challenges related to dataset quality, model convergence, and computational resource management. ","permalink":"http://localhost:1313/projects/lprojects/self-p1/","tags":["Python","Pytorch","GenAI","Pytorch Lightning"],"title":"AI Avatar Generator"},{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"http://localhost:1313/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in Computer Vision and Deep Learning to develop object detection algorithms using 3D cameras/sensors (3D Object Detection Algorithms). These advancements significantly enhance robustness, and capabilities of autonomous systems across wide ranges of applications and industries.\nTargeted applications could be\nSelf-driving Cars: my algorithms help autonomous cars understand theirs surroundings Augmented Reality (AR) and Virtual Reality (VR): my algorithms facilitate the seamless integration of virtual objects into the physical world, elevating the user experience by providing realistic and immersive virtual environments. Industrial Automation: my algorithms can help to inspect components, detect infects automatically. Medical diagnosis: my algorithms can be used for tasks such as tumor detection and organ segmentation. Accomplishments:\nTwo publications about algorithms for 3D object detection. Transferable Skills:\nSolid Understanding of Computer Vision and Deep Learning models, 3D object modelling. Skilled in Python and C++ programming; and utilization of tensorflow, Computer Vision Responsibilities:\nDeveloped a prototype for 3D Object Detection systems, from conceptualization to implementation. ","permalink":"http://localhost:1313/projects/lprojects/self-p5/","tags":["Python","Tensorflow2","Computer Vision","Point Cloud","C++"],"title":"Point Cloud Based 3D Object Detection"},{"categories":null,"contents":" Relevance to the Business:\nLeveraged my expertise in deep learning and Natural Language Processing (NLP) to develop tools for enhancing efficient information retrieval in today\u0026rsquo;s data-driven environment. Targeted at business entities who improve customer support and productivity by automating the extraction of valuable insights from their vast databases. Accomplishments:\nDelivered an attractive Proof of Concept (PoC) to MTI and some private clients, showcasing practical applications. Transferable Skills:\nSolid Understanding of Deep Learning models for NLP, Skilled in Python programming and utilization of NLP libraries such as spaCy, NLTK, transfomer models from hugging face. Responsibilities:\nDeveloped a prototype for Q\u0026amp;A systems, from conceptualization to implementation. ","permalink":"http://localhost:1313/projects/lprojects/self-p4/","tags":["Python","Tensorflow2","GenAI","NLP"],"title":"Question Answering System"},{"categories":null,"contents":" Relevance to the Business:\nEnhance customer experience and engagement by providing tailored product or content suggestions. Accomplishments:\nImplemented collaborative filtering and content-based filtering techniques to generate personalized recommendations. Transferable Skills:\nProficient in machine learning algorithms including standard algorithms for Regression and Classification, Deep Learning constructs (RNN, CNN, Auto Encoders, GANs) and AI systems such as Voice to Text, NLP and Recommender systems. Understanding ML systems using Spark libraries such as ML Lib, Spark SQL. Responsibilities:\nDeveloped recommender systems for product recommendations. Challenges and Difficulties:\nNavigated challenges related to dataset quality, model convergence, and computational resource management. ","permalink":"http://localhost:1313/projects/lprojects/self-p3/","tags":["Python","Tensorflow2","Neo4j"],"title":"Recommendations System"},{"categories":null,"contents":"Relevance to the Business:\nLeveraged my expertise in machine learning, deep learning, and data analytics to pioneer the development of an innovative AI-driven tool for short-term weather forecasting, with a specific focus on predicting hailstorms. Targeted diverse spectrum of Japanese companies, primarily targeting the insurance and car dealership sectors, aimed at elevating risk assessment capabilities by providing exceptionally accurate forecasts. This enhancement in risk assessment holds particular significance for the insurance sector, where weather-related events can exert substantial financial implications. Accomplishments:\nDeveloped a Short-term Hail Nowcast prototype, surpassing the accuracy of the Japan Meteorological Agency\u0026rsquo;s (JMA) forecast system (72% vs. 55%). Delivered a compelling Proof of Concept (PoC) to MS\u0026amp;AD insurance group, showcasing practical applications and superior forecasting capabilities. Transferable Skills:\nAnalytical skills and Quantitative Analysis, Data visualization Knowledge of Geneartive AI Knowledge of Weather and Radar Meteorology. Leadership, project management, and problem-solving skills. Responsibilities:\nLed a data science team, ensuring collaboration between data scientists and industry experts. Mentor the junior team members and support them with technical issues. Translated specific needs of stakeholders into an optimized deep learning model. Challenges and Difficulties:\nRequired a deep understanding of meteorological data and generative deep learning techniques to provide accurate forecasts in a short time frame. Feedback and Endorsements:\nPositive feedback from stakeholders. Context:\nComprehensive background in deep learning and data analytics. Commitment to projects with direct business relevance, contributing to industry advancements. ","permalink":"http://localhost:1313/projects/lprojects/mti-p2/","tags":["Python","Pytorch","GenAI","Computer Vision","AWS","Gitlab"],"title":"Short-term Hail Nowcast Using AI for Extreme Weather Events"},{"categories":null,"contents":"Relevance to the Business:\nApplied machine learning, deep learning and data analytics expertise to develop a sophisticated typesetting tool. Targeted specifically for Japanese newspapers, aimed at enhancing efficiency, quality of layout design and cost reduction. Accomplishments:\nSecured a patent for the Typesetting API. Delivered a Proof of Concept (PoC) to renowned companies like Toshiba and Fujitsu. Transferable Skills:\nKnowledge of state of the art machine learning methodologies and their business applications in python (sklearn, pytorch, flask, fastapi) Knowledge of IT and Cluster technologies: Docker, Gitlab. Analytical skill, Data visualization, Constraint Programming and Deep Reinforcement Learning (Proximal Policy Optimization). Leadership, project management, and problem-solving skills. Responsibilities:\nLed a multidisciplinary team, ensuring collaboration between data scientist, software developers, data analyst, and industry experts. Mentor the junior team members and support them with technical issues. Translated specific needs of Japanese newspapers into an optimized machine learning model. Oversaw the end-to-end development of predictive models using advanced machine learning algorithms. Challenges and Difficulties:\nRequired understanding the unique preferences of the Japanese market, and design principles. Demonstrated problem-solving skills at the intersection of machine learning and Japanese design. Feedback and Endorsements:\nReceived positive feedback from stakeholders on efficiency and quality improvements. Endorsements affirm tangible contributions to the business landscape. Context:\nComprehensive background in deep learning and data analytics. Commitment to projects with direct business relevance, contributing to industry advancements. ","permalink":"http://localhost:1313/projects/lprojects/mti-p1/","tags":["Python","Pytorch","Reinforcement Learning","AWS",".NET","Gitlab"],"title":"Typesetting – AI-based Newspaper Placement Tool for the Japanese market."},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\nDon’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution. ","permalink":"http://localhost:1313/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"http://localhost:1313/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"http://localhost:1313/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":" \u0026emsp; The newsroom is a whirlwind of activity, with editors juggling deadlines, reporters chasing stories, and designers wrestling with stacks of paper and design software. Among these challenges, the process of typesetting – arranging articles, images, and advertisements on the page – stands out as a particularly time-consuming and labor-intensive task. But what if this critical step could be streamlined and enhanced with the power of artificial intelligence? See demonstration !!! I. The Pain Points of Traditional Typesetting \u0026emsp; Traditionally, typesetting is a manual and often tedious process. Designers meticulously arrange elements on the page, considering factors like headline size, image placement, and column widths. This meticulous work is prone to human error, leading to inconsistencies in layout and potential for missed deadlines. The pressure to meet tight deadlines adds to the stress, hindering creativity and the ability to explore diverse and innovative design solutions. The process is illustrated in the Figure below Typical typesetting process used in newspaper company\nFig 1. Current Manual Process 1 Fig 2. Manual Process - Making rough layout Fig 3. Manual Process - Making layout arrangement on computer The process last about 12 hours and it is very stressful.\nII. Solutions: Automating the Art of Layout \u0026emsp; By leveraging constraint optimization and Reinforcement Learning (a sub-field of Machine Learning) techniques, I developed a novel solution that automates the typesetting process, significantly reducing the time required and minimizing the risk of human errors. This AI solution was implemented as a proof of concept and was showcased to ToO newspaper company. Intelligent Content Placement: The AI system analyzes articles, images, and advertisements, intelligently suggesting optimal placements on the page. Automated Layout Generation: The AI can generate multiple layout options, allowing designers to quickly explore different possibilities and choose the most effective design. Image Optimization: The system automatically resizes and optimizes images for print, ensuring high-quality reproduction. Fig 4. The proposed automated typesetting process Fig 5. The proposed typesetting (left) process and visualization of the proposed framework (right) Fig 6. Visualization of states of the proposed framework III. The Benefits Speak for Themselves \u0026emsp; By automating many of the mundane tasks, AI-powered typesetting significantly enhances efficiency and productivity. Reduced Workload: Designers can spend less time on repetitive tasks and more time on creative aspects of design. Faster Turnaround Times: Newspapers can be produced more quickly, enabling faster news dissemination. Improved Consistency: AI helps ensure consistent layouts across different editions and publications, enhancing brand identity. Enhanced Creativity: Designers are empowered to explore a wider range of layout options and experiment with innovative design concepts. IV. Beyond Typesetting: A Catalyst for Innovation \u0026emsp; The successful application of AI in newspaper typesetting demonstrates its broader potential across various industries. Magazine and Book Publishing: Streamline the layout and design of magazines, books, and other print publications. Graphic Design and Advertising: Automate aspects of brochure, poster, and billboard design. Website and App Design: Assist in the creation of visually appealing and user-friendly interfaces. Industrial Manufacturing and Production: Optimize production processes and improve efficiency in various manufacturing settings. V. The Future of AI in Design \u0026emsp; The integration of AI into the design process marks a significant step forward. By automating repetitive tasks and augmenting human creativity, AI has the potential to revolutionize how we approach design in the 21st century. As AI technology continues to evolve, we can expect even more sophisticated and innovative applications in the years to come, ushering in a new era of creativity and efficiency across diverse industries. This blog post provides a glimpse into the transformative power of AI in the field of newspaper design. By embracing these innovative technologies, the publishing industry can not only improve its efficiency but also unlock new levels of creativity and innovation in the years to come.\nVI. Demonstrations ","permalink":"http://localhost:1313/blog/typesetting/","tags":["Python","Pytorch","Reinforcement Learning","Deep Learning","Constrained Programming"],"title":"Revolutionizing Newspaper Design: How AI is Automating Typesetting"},{"categories":null,"contents":"BOSH (Bosh Outer SHell) \u0026ldquo;\u0026hellip; is an open source tool for release engineering, deployment, lifecycle management, and monitoring of distributed systems.\u0026rdquo; And it\u0026rsquo;s amazingly powerful. This examples uses BOSH to provision an Alassian vendor app running on JDK along with the support Postgres database and agents to support it. The releases manages the health of services and will automatically provision, start/stop processes across the various services.\n","permalink":"http://localhost:1313/projects/creations/bosh-agents/","tags":["DevOps","BOSH","Java","Atlassian Ecosystem","monit","python","xml/xslt","bash/shell","REST APIs"],"title":"BOSH release for Bamboo \u0026 Remote Agents"},{"categories":null,"contents":" \u0026emsp; This project focuses on developing an advanced AI-based system for early detection of extreme weather events in Japan. By leveraging cutting-edge machine learning algorithms and analyzing vast amounts of historical weather data, this system aims to: Improve accuracy and lead time: Provide more accurate and timely predictions of severe weather events, such as intense rainfall, strong winds, and heavy snowfall. Enhance early warning systems: Empower weather information service providers to issue more precise and timely warnings to the public, allowing for swift evacuation and precautionary measures. Reduce human error: Minimize the impact of human error in weather forecasting by automating data analysis and prediction processes. Enable proactive risk management: Equip individuals, businesses, and government agencies with the necessary information to proactively assess risks and implement effective mitigation strategies. See demonstration !!! I. Key benefits of this AI-powered weather prediction system Save lives: Enable timely evacuations and reduce casualties during severe weather events. Minimize property damage: Allow for proactive measures to protect homes, businesses, and critical infrastructure. Support informed decision-making: Provide valuable data for emergency responders, disaster relief agencies, and government officials. Enhance public awareness: Raise public awareness about the dangers of severe weather and promote preparedness. This project represents a significant step towards a more proactive and data-driven approach to weather forecasting in Japan. By harnessing the power of AI, we can build a more resilient and safer society, better prepared to face the challenges of the future.\nII. Solutions III. Demonstration ","permalink":"http://localhost:1313/blog/weather/","tags":["Python","Pytorch","GenAI","Computer Vision","AWS","Gitlab","Weather"],"title":"Predicting the Unpredictable: AI-Powered Weather Forecasting for Severe Events in Japan"},{"categories":null,"contents":"Multiple plugins used by thousands of teams that provide enhanced functionality of Atlassian’s core products (primarily JIRA and Bamboo) to enrich CI/CD capabilities, DevOps automation, or productivity. Functionality spans user interface, web services and persistence.\n","permalink":"http://localhost:1313/projects/creations/marketplace/","tags":["Java","Spring","REST APIs","Javascript","Atlassian Developer Ecosystem","Bamboo","JIRA","Bitbucket","Confluence","DevOps"],"title":"Atlassian Marketplace Plugins"},{"categories":null,"contents":"Provides required dependencies and additional utilities to simplify and codify the process of building, testing and delivering Atlassian plugins all the way to the live marketplace. Executes integration/AUT level tests against all stated compatible versions for the productUploads generated artifact to Atlassian marketplaceProvides corresponding metadata indicating version, release notes, and compatibility\n","permalink":"http://localhost:1313/projects/creations/docker-marketplace/","tags":["Docker","Maven","Java","Python","REST APIs","Bash/Shell"],"title":"Docker image for Bitbucket CI/CD Pipelines  \"shipit\""},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"http://localhost:1313/search/","tags":null,"title":"Search Results"}]